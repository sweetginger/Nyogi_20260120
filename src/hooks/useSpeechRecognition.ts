'use client'

import { useState, useEffect, useCallback, useRef } from 'react'

interface SpeechRecognitionResult {
  transcript: string
  isFinal: boolean
  confidence: number
}

interface UseSpeechRecognitionOptions {
  language: string
  continuous?: boolean
  interimResults?: boolean
  onResult?: (result: SpeechRecognitionResult) => void
  onError?: (error: string) => void
  onEnd?: () => void
}

interface UseSpeechRecognitionReturn {
  isListening: boolean
  isSupported: boolean
  transcript: string
  interimTranscript: string
  startListening: () => void
  stopListening: () => void
  resetTranscript: () => void
}

// Web Speech API íƒ€ì… ì •ì˜
interface SpeechRecognitionEvent extends Event {
  results: SpeechRecognitionResultList
  resultIndex: number
}

interface SpeechRecognitionResultList {
  length: number
  item(index: number): SpeechRecognitionResult
  [index: number]: SpeechRecognitionResult
}

interface SpeechRecognitionResult {
  isFinal: boolean
  length: number
  item(index: number): SpeechRecognitionAlternative
  [index: number]: SpeechRecognitionAlternative
}

interface SpeechRecognitionAlternative {
  transcript: string
  confidence: number
}

interface SpeechRecognitionErrorEvent extends Event {
  error: string
  message: string
}

interface SpeechRecognition extends EventTarget {
  continuous: boolean
  interimResults: boolean
  lang: string
  maxAlternatives: number
  start(): void
  stop(): void
  abort(): void
  onstart: ((this: SpeechRecognition, ev: Event) => void) | null
  onend: ((this: SpeechRecognition, ev: Event) => void) | null
  onaudiostart: ((this: SpeechRecognition, ev: Event) => void) | null
  onsoundstart: ((this: SpeechRecognition, ev: Event) => void) | null
  onspeechstart: ((this: SpeechRecognition, ev: Event) => void) | null
  onresult: ((this: SpeechRecognition, ev: SpeechRecognitionEvent) => void) | null
  onerror: ((this: SpeechRecognition, ev: SpeechRecognitionErrorEvent) => void) | null
}

declare global {
  interface Window {
    SpeechRecognition: new () => SpeechRecognition
    webkitSpeechRecognition: new () => SpeechRecognition
  }
}

// ì¬ì‹œì‘ ì„¤ì •
const RESTART_DELAY_MS = 300 // ì¬ì‹œì‘ ê¸°ë³¸ ë”œë ˆì´
const MAX_RESTART_DELAY_MS = 5000 // ìµœëŒ€ ë”œë ˆì´ (ë°±ì˜¤í”„)
const MAX_CONSECUTIVE_ERRORS = 5 // ì—°ì† ì—ëŸ¬ ìµœëŒ€ íšŸìˆ˜
const RECOGNITION_REFRESH_INTERVAL = 60000 // 1ë¶„ë§ˆë‹¤ recognition ê°ì²´ ê°±ì‹ 

export function useSpeechRecognition({
  language,
  continuous = true,
  interimResults = true,
  onResult,
  onError,
  onEnd,
}: UseSpeechRecognitionOptions): UseSpeechRecognitionReturn {
  const [isListening, setIsListening] = useState(false)
  const [isSupported, setIsSupported] = useState(false)
  const [transcript, setTranscript] = useState('')
  const [interimTranscript, setInterimTranscript] = useState('')
  
  const recognitionRef = useRef<SpeechRecognition | null>(null)
  const shouldBeListeningRef = useRef(false)
  const isRestartingRef = useRef(false)
  const restartTimeoutRef = useRef<NodeJS.Timeout | null>(null)
  const consecutiveErrorsRef = useRef(0)
  const lastSuccessTimeRef = useRef(Date.now())
  const refreshIntervalRef = useRef<NodeJS.Timeout | null>(null)
  
  // ì½œë°± í•¨ìˆ˜ë“¤ì„ refë¡œ ì €ì¥
  const onResultRef = useRef(onResult)
  const onErrorRef = useRef(onError)
  const onEndRef = useRef(onEnd)
  const languageRef = useRef(language)
  
  useEffect(() => { onResultRef.current = onResult }, [onResult])
  useEffect(() => { onErrorRef.current = onError }, [onError])
  useEffect(() => { onEndRef.current = onEnd }, [onEnd])
  useEffect(() => { languageRef.current = language }, [language])

  // SpeechRecognition ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
  const createRecognition = useCallback(() => {
    const SpeechRecognitionAPI =
      typeof window !== 'undefined' &&
      (window.SpeechRecognition || window.webkitSpeechRecognition)
    
    if (!SpeechRecognitionAPI) return null

    const recognition = new SpeechRecognitionAPI()
    recognition.continuous = continuous
    recognition.interimResults = interimResults
    recognition.maxAlternatives = 1
    recognition.lang = getLanguageCode(languageRef.current)

    recognition.onstart = () => {
      console.log('[Speech] âœ… Started')
      setIsListening(true)
      isRestartingRef.current = false
      consecutiveErrorsRef.current = 0
    }

    recognition.onaudiostart = () => {
      console.log('[Speech] ğŸ¤ Audio started')
    }

    recognition.onspeechstart = () => {
      console.log('[Speech] ğŸ—£ï¸ Speech detected')
      lastSuccessTimeRef.current = Date.now()
    }

    recognition.onend = () => {
      console.log('[Speech] â¹ï¸ Ended, shouldListen:', shouldBeListeningRef.current)
      setIsListening(false)
      onEndRef.current?.()
      
      // ì‚¬ìš©ìê°€ ë“£ê¸°ë¥¼ ì›í•˜ê³ , ì¬ì‹œì‘ ì¤‘ì´ ì•„ë‹ˆë©´ ì¬ì‹œì‘
      if (shouldBeListeningRef.current && !isRestartingRef.current) {
        scheduleRestart()
      }
    }

    recognition.onresult = (event: SpeechRecognitionEvent) => {
      let finalTranscript = ''
      let interim = ''

      for (let i = event.resultIndex; i < event.results.length; i++) {
        const result = event.results[i]
        const text = result[0].transcript

        if (result.isFinal) {
          finalTranscript += text
          console.log('[Speech] ğŸ“ Final:', text.substring(0, 50) + (text.length > 50 ? '...' : ''))
          
          // ì„±ê³µ ì‹œ ì—ëŸ¬ ì¹´ìš´í„° ë¦¬ì…‹
          consecutiveErrorsRef.current = 0
          lastSuccessTimeRef.current = Date.now()
          
          onResultRef.current?.({
            transcript: text,
            isFinal: true,
            confidence: result[0].confidence,
          })
        } else {
          interim += text
        }
      }

      if (finalTranscript) {
        setTranscript((prev) => prev + finalTranscript)
        setInterimTranscript('')
      } else {
        setInterimTranscript(interim)
      }
    }

    recognition.onerror = (event: SpeechRecognitionErrorEvent) => {
      console.warn('[Speech] âš ï¸ Error:', event.error)
      
      // ë³µêµ¬ ê°€ëŠ¥í•œ ì—ëŸ¬ ì²˜ë¦¬
      if (event.error === 'no-speech') {
        // ìŒì„± ì—†ìŒ - ì •ìƒì ì¸ ìƒí™©, ì¬ì‹œì‘
        if (shouldBeListeningRef.current) {
          scheduleRestart(500)
        }
        return
      }

      if (event.error === 'aborted') {
        // ìˆ˜ë™ ì¤‘ë‹¨ - ë¬´ì‹œ
        return
      }

      if (event.error === 'network') {
        // ë„¤íŠ¸ì›Œí¬ ì—ëŸ¬ - ì ì‹œ í›„ ì¬ì‹œì‘
        consecutiveErrorsRef.current++
        if (shouldBeListeningRef.current && consecutiveErrorsRef.current < MAX_CONSECUTIVE_ERRORS) {
          const delay = Math.min(
            RESTART_DELAY_MS * Math.pow(2, consecutiveErrorsRef.current),
            MAX_RESTART_DELAY_MS
          )
          console.log(`[Speech] ğŸ”„ Network error, retrying in ${delay}ms...`)
          scheduleRestart(delay)
        }
        return
      }

      if (event.error === 'audio-capture') {
        // ì˜¤ë””ì˜¤ ìº¡ì²˜ ì‹¤íŒ¨ - ë§ˆì´í¬ ë¬¸ì œ
        consecutiveErrorsRef.current++
        if (shouldBeListeningRef.current && consecutiveErrorsRef.current < MAX_CONSECUTIVE_ERRORS) {
          scheduleRestart(1000)
        } else {
          onErrorRef.current?.('ë§ˆì´í¬ ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.')
          shouldBeListeningRef.current = false
        }
        return
      }

      // ê¸°íƒ€ ì—ëŸ¬
      const errorMessage = getErrorMessage(event.error)
      onErrorRef.current?.(errorMessage)
      setIsListening(false)
      shouldBeListeningRef.current = false
    }

    return recognition
  }, [continuous, interimResults])

  // ì¬ì‹œì‘ ìŠ¤ì¼€ì¤„ë§
  const scheduleRestart = useCallback((delay: number = RESTART_DELAY_MS) => {
    if (restartTimeoutRef.current) {
      clearTimeout(restartTimeoutRef.current)
    }

    if (!shouldBeListeningRef.current) return

    isRestartingRef.current = true
    console.log(`[Speech] ğŸ”„ Scheduling restart in ${delay}ms...`)

    restartTimeoutRef.current = setTimeout(() => {
      if (!shouldBeListeningRef.current) {
        isRestartingRef.current = false
        return
      }

      const recognition = recognitionRef.current
      if (recognition) {
        try {
          recognition.lang = getLanguageCode(languageRef.current)
          recognition.start()
        } catch (e) {
          console.warn('[Speech] Restart failed:', e)
          // ì¸ìŠ¤í„´ìŠ¤ ë¬¸ì œì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ìƒˆë¡œ ìƒì„±
          refreshRecognition()
        }
      } else {
        refreshRecognition()
      }
    }, delay)
  }, [])

  // Recognition ì¸ìŠ¤í„´ìŠ¤ ê°±ì‹ 
  const refreshRecognition = useCallback(() => {
    console.log('[Speech] ğŸ”ƒ Refreshing recognition instance...')
    
    // ê¸°ì¡´ ì¸ìŠ¤í„´ìŠ¤ ì •ë¦¬
    if (recognitionRef.current) {
      try {
        recognitionRef.current.abort()
      } catch {
        // ë¬´ì‹œ
      }
    }

    // ìƒˆ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    recognitionRef.current = createRecognition()
    
    if (recognitionRef.current && shouldBeListeningRef.current) {
      setTimeout(() => {
        try {
          recognitionRef.current?.start()
        } catch (e) {
          console.error('[Speech] Failed to start after refresh:', e)
        }
      }, 100)
    }
  }, [createRecognition])

  // ë¸Œë¼ìš°ì € ì§€ì› í™•ì¸ ë° ì´ˆê¸°í™”
  useEffect(() => {
    const SpeechRecognitionAPI =
      typeof window !== 'undefined' &&
      (window.SpeechRecognition || window.webkitSpeechRecognition)
    
    setIsSupported(!!SpeechRecognitionAPI)

    if (SpeechRecognitionAPI) {
      recognitionRef.current = createRecognition()
    }

    return () => {
      shouldBeListeningRef.current = false
      if (restartTimeoutRef.current) {
        clearTimeout(restartTimeoutRef.current)
      }
      if (refreshIntervalRef.current) {
        clearInterval(refreshIntervalRef.current)
      }
      if (recognitionRef.current) {
        try {
          recognitionRef.current.abort()
        } catch {
          // ë¬´ì‹œ
        }
      }
    }
  }, [createRecognition])

  // ì£¼ê¸°ì  ì¸ìŠ¤í„´ìŠ¤ ê°±ì‹  (ì¥ì‹œê°„ ì‚¬ìš© ì‹œ ì•ˆì •ì„±)
  useEffect(() => {
    if (shouldBeListeningRef.current) {
      refreshIntervalRef.current = setInterval(() => {
        const timeSinceLastSuccess = Date.now() - lastSuccessTimeRef.current
        
        // ë§ˆì§€ë§‰ ì„±ê³µ í›„ 30ì´ˆ ì´ìƒ ì§€ë‚¬ìœ¼ë©´ ê°±ì‹ 
        if (timeSinceLastSuccess > 30000) {
          console.log('[Speech] â™»ï¸ Periodic refresh due to inactivity')
          refreshRecognition()
        }
      }, RECOGNITION_REFRESH_INTERVAL)
    }

    return () => {
      if (refreshIntervalRef.current) {
        clearInterval(refreshIntervalRef.current)
      }
    }
  }, [refreshRecognition])

  // ì–¸ì–´ ë³€ê²½ ì‹œ ì¬ì‹œì‘
  useEffect(() => {
    if (recognitionRef.current && isListening) {
      recognitionRef.current.lang = getLanguageCode(language)
      // ì–¸ì–´ ë³€ê²½ì„ ì ìš©í•˜ê¸° ìœ„í•´ ì¬ì‹œì‘
      try {
        recognitionRef.current.stop()
      } catch {
        // ë¬´ì‹œ
      }
      // onendì—ì„œ ìë™ ì¬ì‹œì‘ë¨
    }
  }, [language, isListening])

  const startListening = useCallback(() => {
    if (!isSupported) {
      onError?.('ìŒì„± ì¸ì‹ì´ ì§€ì›ë˜ì§€ ì•ŠëŠ” ë¸Œë¼ìš°ì €ì…ë‹ˆë‹¤.')
      return
    }

    console.log('[Speech] â–¶ï¸ Start requested')
    shouldBeListeningRef.current = true
    consecutiveErrorsRef.current = 0
    lastSuccessTimeRef.current = Date.now()

    // ì¸ìŠ¤í„´ìŠ¤ê°€ ì—†ìœ¼ë©´ ìƒì„±
    if (!recognitionRef.current) {
      recognitionRef.current = createRecognition()
    }

    const recognition = recognitionRef.current
    if (!recognition) {
      onError?.('ìŒì„± ì¸ì‹ì„ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
      return
    }

    recognition.lang = getLanguageCode(language)
    
    try {
      recognition.start()
    } catch (e) {
      console.warn('[Speech] Start error, recreating:', e)
      // ì¸ìŠ¤í„´ìŠ¤ ë¬¸ì œì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ìƒˆë¡œ ìƒì„±
      refreshRecognition()
    }
  }, [isSupported, language, onError, createRecognition, refreshRecognition])

  const stopListening = useCallback(() => {
    console.log('[Speech] â¸ï¸ Stop requested')
    shouldBeListeningRef.current = false
    isRestartingRef.current = false
    
    if (restartTimeoutRef.current) {
      clearTimeout(restartTimeoutRef.current)
      restartTimeoutRef.current = null
    }

    setInterimTranscript('')
    
    const recognition = recognitionRef.current
    if (recognition) {
      try {
        recognition.stop()
      } catch {
        // ì´ë¯¸ ì¤‘ì§€ëœ ê²½ìš° ë¬´ì‹œ
      }
    }
    setIsListening(false)
  }, [])

  const resetTranscript = useCallback(() => {
    setTranscript('')
    setInterimTranscript('')
  }, [])

  return {
    isListening,
    isSupported,
    transcript,
    interimTranscript,
    startListening,
    stopListening,
    resetTranscript,
  }
}

// ì–¸ì–´ ì½”ë“œ ë³€í™˜
function getLanguageCode(lang: string): string {
  const languageMap: Record<string, string> = {
    ko: 'ko-KR',
    en: 'en-US',
    ja: 'ja-JP',
    zh: 'zh-CN',
    es: 'es-ES',
    fr: 'fr-FR',
    de: 'de-DE',
    pt: 'pt-BR',
    ru: 'ru-RU',
    ar: 'ar-SA',
  }
  return languageMap[lang] || lang
}

// ì—ëŸ¬ ë©”ì‹œì§€ ë³€í™˜
function getErrorMessage(error: string): string {
  const errorMessages: Record<string, string> = {
    'not-allowed': 'ë§ˆì´í¬ ì ‘ê·¼ì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì—ì„œ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.',
    'no-speech': 'ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.',
    'audio-capture': 'ë§ˆì´í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
    'network': 'ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
    'aborted': 'ìŒì„± ì¸ì‹ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.',
    'language-not-supported': 'ì§€ì›ë˜ì§€ ì•ŠëŠ” ì–¸ì–´ì…ë‹ˆë‹¤.',
    'service-not-allowed': 'ìŒì„± ì¸ì‹ ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
  }
  return errorMessages[error] || `ìŒì„± ì¸ì‹ ì˜¤ë¥˜: ${error}`
}
